{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "import re\n",
    "import contractions\n",
    "import string\n",
    "\n",
    "from more_itertools import sort_together\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim import similarities\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/jobs_labelled.csv', index_col=0)\n",
    "\n",
    "with open('data/reference.json') as json_file:\n",
    "    term2ka = json.load(json_file)\n",
    "\n",
    "knowledge_areas = [\n",
    "    'AAA',\n",
    "    'AC',\n",
    "    'AB',\n",
    "    'C',\n",
    "    'CI',\n",
    "    'CPS',\n",
    "    'DSS',\n",
    "    'F',\n",
    "    'FMS',\n",
    "    'HF',\n",
    "    'HS',\n",
    "    'LR',\n",
    "    'MAT',\n",
    "    'NS',\n",
    "    'OSV',\n",
    "    'PLT',\n",
    "    'POR',\n",
    "    'RMG',\n",
    "    'SOIM',\n",
    "    'SS',\n",
    "    'SSL',\n",
    "    'WAM'\n",
    "]\n",
    "\n",
    "knowledge_groups = [\n",
    "    'Introduction',\n",
    "    'Human, Org., & Reg.',\n",
    "    'Attacks & Defences',\n",
    "    'Systems',\n",
    "    'Software & Platform',\n",
    "    'Infrastructure'\n",
    "]\n",
    "\n",
    "ka2doc = {\n",
    "    'AAA': \"\",\n",
    "    'AC': \"\",\n",
    "    'AB': \"\",\n",
    "    'C': \"\",\n",
    "    'CI': \"\",\n",
    "    'CPS': \"\",\n",
    "    'DSS': \"\",\n",
    "    'F': \"\",\n",
    "    'FMS': \"\",\n",
    "    'HF': \"\",\n",
    "    'HS': \"\",\n",
    "    'LR': \"\",\n",
    "    'MAT': \"\",\n",
    "    'NS': \"\",\n",
    "    'OSV': \"\",\n",
    "    'PLT': \"\",\n",
    "    'POR': \"\",\n",
    "    'RMG': \"\",\n",
    "    'SOIM': \"\",\n",
    "    'SS': \"\",\n",
    "    'SSL': \"\",\n",
    "    'WAM': \"\"\n",
    "}\n",
    "\n",
    "ka2group = {\n",
    "    'AAA': \"Systems\",\n",
    "    'AC': \"Infrastructure\",\n",
    "    'AB': \"Attacks & Defences\",\n",
    "    'C': \"Systems\",\n",
    "    'CI': \"Introduction\",\n",
    "    'CPS': \"Infrastructure\",\n",
    "    'DSS': \"Systems\",\n",
    "    'F': \"Attacks & Defences\",\n",
    "    'FMS': \"Systems\",\n",
    "    'HF': \"Human, Org., & Reg.\",\n",
    "    'HS': \"Infrastructure\",\n",
    "    'LR': \"Human, Org., & Reg.\",\n",
    "    'MAT': \"Attacks & Defences\",\n",
    "    'NS': \"Infrastructure\",\n",
    "    'OSV': \"Systems\",\n",
    "    'PLT': \"Infrastructure\",\n",
    "    'POR': \"Human, Org., & Reg.\",\n",
    "    'RMG': \"Human, Org., & Reg.\",\n",
    "    'SOIM': \"Attacks & Defences\",\n",
    "    'SS': \"Software & Platform\",\n",
    "    'SSL': \"Software & Platform\",\n",
    "    'WAM': \"Software & Platform\"\n",
    "}\n",
    "\n",
    "group2doc = {\n",
    "    'Introduction': \"\",\n",
    "    'Human, Org., & Reg.': \"\",\n",
    "    'Attacks & Defences': \"\",\n",
    "    'Systems': \"\",\n",
    "    'Software & Platform': \"\",\n",
    "    'Infrastructure': \"\"\n",
    "}\n",
    "\n",
    "ka2long = {\n",
    "    'AAA': 'Authentication, Authorisation & Accountability',\n",
    "    'AC': 'Applied Cryptography',\n",
    "    'AB': 'Adversarial Behaviours',\n",
    "    'C': 'Cryptography',\n",
    "    'CI': 'CyBOK Introduction',\n",
    "    'CPS': 'Cyber-Physical Systems Security',\n",
    "    'DSS': 'Distributed Systems Security',\n",
    "    'F': 'Forensics',\n",
    "    'FMS': 'Formal Methods for Security',\n",
    "    'HF': 'Human Factors',\n",
    "    'HS': 'Hardware Security',\n",
    "    'LR': 'Law & Regulation',\n",
    "    'MAT': 'Malware & Attack Technologies',\n",
    "    'NS': 'Network Security',\n",
    "    'OSV': 'Operating Systems & Virtualisation',\n",
    "    'PLT': 'Physical Layer & Telecommunications Security',\n",
    "    'POR': 'Privacy & Online Rights',\n",
    "    'RMG': 'Risk Management & Governance',\n",
    "    'SOIM': 'Security Operations & Incident Management',\n",
    "    'SS': 'Software Security',\n",
    "    'SSL': 'Secure Software Lifecycle',\n",
    "    'WAM': 'Web & Mobile Security'\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data vis. Source: https://colorbrewer2.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pal = ['#8dd3c7','#ffffb3','#bebada','#fb8072','#80b1d3','#fdb462','#b3de69','#fccde5','#d9d9d9','#bc80bd','#ccebc5','#ffed6f']\n",
    "sns.palplot(pal)\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\", palette=pal)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make new corpora\n",
    "\n",
    "##### Each ka being a document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For *ka_tf-idf*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ka in knowledge_areas:\n",
    "    for term in term2ka.keys():\n",
    "        if ka in term2ka[term]:\n",
    "            ka2doc[ka] += term + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2ka = {}\n",
    "for ka in ka2doc.keys():\n",
    "    doc = ka2doc[ka]\n",
    "    doc2ka[doc] = ka"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For *kg_tf-idf*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ka in knowledge_areas:\n",
    "    for term in term2ka.keys():\n",
    "        if ka in term2ka[term]:\n",
    "            group2doc[ka2group[ka]] += term + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2group = {}\n",
    "for group in group2doc.keys():\n",
    "    doc = group2doc[group]\n",
    "    doc2group[doc] = group"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building tf-idf representations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils. for building the representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfidfMapper():\n",
    "    def __init__(self, tfidf, dictionary, corpus, documents):\n",
    "        self.tfidf = tfidf\n",
    "        self.dictionary = dictionary\n",
    "        self.corpus = corpus\n",
    "        self.documents = documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # remove url links\n",
    "    text = re.sub('(http|https):\\/\\/\\S+', \"\", text)\n",
    "\n",
    "    # remove contractions (e.g. I've > I have)\n",
    "    text = contractions.fix(text)\n",
    "\n",
    "    # remove stopwords\n",
    "    token_list = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    token_list = [token for token in token_list if token not in stop_words]\n",
    "    text = TreebankWordDetokenizer().detokenize(token_list)\n",
    "\n",
    "    # remove punctuation\n",
    "    token_list = word_tokenize(text)\n",
    "    token_list = [token for token in token_list if token not in string.punctuation]\n",
    "    text = TreebankWordDetokenizer().detokenize(token_list)\n",
    "\n",
    "    # convert to uppercase\n",
    "    text = text.upper()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ka_tfidf(ka2doc, calc_results=True):\n",
    "    documents = []\n",
    "    for ka in knowledge_areas:\n",
    "        if ka != 'CI': # exclude the introduction KA\n",
    "            documents.append(ka2doc[ka])\n",
    "\n",
    "    processed_documents = [preprocess(document) for document in documents]\n",
    "\n",
    "    tokenized_documents = [word_tokenize(document) for document in processed_documents]\n",
    "\n",
    "    dictionary = Dictionary(tokenized_documents)\n",
    "\n",
    "    corpus = [dictionary.doc2bow(document) for document in tokenized_documents] # in matrix market format\n",
    "\n",
    "    tfidf = TfidfModel(corpus)\n",
    "\n",
    "    mapper = TfidfMapper(tfidf, dictionary, corpus, documents)\n",
    "\n",
    "    tfidf_results = pd.DataFrame(columns=['token', 'document', 'tfidf'])\n",
    "    if (calc_results):\n",
    "        for idx, document in enumerate(corpus):\n",
    "            token_weights = tfidf[document]\n",
    "            for token_weight in token_weights:\n",
    "                tfidf_results.loc[len(tfidf_results.index)] = [\n",
    "                    dictionary[token_weight[0]],\n",
    "                    documents[idx],\n",
    "                    token_weight[1]\n",
    "                ]\n",
    "    \n",
    "    return mapper, tfidf_results\n",
    "\n",
    "def make_kg_tfidf(group2doc, calc_results=True):\n",
    "    documents = []\n",
    "    for kg in knowledge_groups:\n",
    "        if kg != 'Introduction': # exclude the introductory group\n",
    "            documents.append(group2doc[kg])\n",
    "\n",
    "    processed_documents = [preprocess(document) for document in documents]\n",
    "    \n",
    "    tokenized_documents = [word_tokenize(document) for document in processed_documents]\n",
    "\n",
    "    dictionary = Dictionary(tokenized_documents)\n",
    "\n",
    "    corpus = [dictionary.doc2bow(document) for document in tokenized_documents] # in matrix market format\n",
    "\n",
    "    tfidf = TfidfModel(corpus)\n",
    "\n",
    "    mapper = TfidfMapper(tfidf, dictionary, corpus, documents)\n",
    "\n",
    "    tfidf_results = pd.DataFrame(columns=['token', 'document', 'tfidf'])\n",
    "    if (calc_results):\n",
    "        for idx, document in enumerate(corpus):\n",
    "            token_weights = tfidf[document]\n",
    "            for token_weight in token_weights:\n",
    "                tfidf_results.loc[len(tfidf_results.index)] = [\n",
    "                    dictionary[token_weight[0]],\n",
    "                    documents[idx],\n",
    "                    token_weight[1]\n",
    "                ]\n",
    "    \n",
    "    return mapper, tfidf_results\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling from both representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper, results = make_ka_tfidf(ka2doc)\n",
    "results.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_mapper, kg_results = make_kg_tfidf(group2doc)\n",
    "kg_results.sample(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping utils. for calculating similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map(mapper, query_doc):\n",
    "    query_doc = preprocess(query_doc)\n",
    "\n",
    "    # calc sims\n",
    "    vec_bow = mapper.dictionary.doc2bow(query_doc.split())\n",
    "    vec_tfidf = mapper.tfidf[vec_bow]\n",
    "    index = similarities.MatrixSimilarity(mapper.tfidf[mapper.corpus])\n",
    "    sims = index[vec_tfidf]\n",
    "\n",
    "    # map to kas\n",
    "    ka2score = {}\n",
    "    for doc_position, doc_score in sorted(enumerate(sims), key=lambda item: item[1]):\n",
    "        ka2score[doc2ka[mapper.documents[doc_position]]] = doc_score\n",
    "\n",
    "    return ka2score\n",
    "\n",
    "def map_groups(mapper, query_doc):\n",
    "    query_doc = preprocess(query_doc)\n",
    "\n",
    "    # calc sims\n",
    "    vec_bow = mapper.dictionary.doc2bow(query_doc.split())\n",
    "    vec_tfidf = mapper.tfidf[vec_bow]\n",
    "    index = similarities.MatrixSimilarity(mapper.tfidf[mapper.corpus])\n",
    "    sims = index[vec_tfidf]\n",
    "\n",
    "    # map to kas\n",
    "    group2score = {}\n",
    "    for doc_position, doc_score in sorted(enumerate(sims), key=lambda item: item[1]):\n",
    "        group2score[doc2group[mapper.documents[doc_position]]] = doc_score\n",
    "\n",
    "    return group2score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Illustrative mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgs_df = df.loc[df['Title'].str.contains(\"Data Governance Specialist\", case=False)]\n",
    "dgs_df.head(12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the description is yet to be normalised (this happens as a part of the mapping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_doc = dgs_df['Description'].values[0]\n",
    "query_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgs_ka2score = map(mapper, query_doc)\n",
    "dgs_group2score = map_groups(kg_mapper, query_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mapping(ka2count, _color, _ax=None, trim=0):\n",
    "    plt.figure(figsize=(11,7))\n",
    "\n",
    "    # defining data and chart labels\n",
    "    sorted = sort_together([ka2count.values(), ka2count.keys()], reverse=True)\n",
    "    x = list(sorted[0])\n",
    "    y = list(sorted[1])\n",
    "\n",
    "    if trim != 0:\n",
    "        x = x[:trim]\n",
    "        y = y[:trim]\n",
    "\n",
    "    axis_labels = ['no. hits', '']\n",
    "    data_labels = []\n",
    "\n",
    "    # make chart\n",
    "    sns.barplot(x=x, y=y, color='#8dd3c7')\n",
    "    plt.xticks(fontsize=10, color='DimGrey')\n",
    "    plt.yticks(fontsize=10, color='DimGrey')\n",
    "    plt.gca().spines['left'].set_color('DimGrey')\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.gca().spines['bottom'].set_color('DimGrey')\n",
    "    plt.xlabel(axis_labels[0], fontsize=12, color='DimGrey', loc='left')\n",
    "    plt.ylabel(axis_labels[1], fontsize=12, color='DimGrey', loc='top')\n",
    "\n",
    "    if _ax == None:\n",
    "        sns.barplot(x=x, y=y, color=_color)\n",
    "    else:\n",
    "        _ = sns.barplot(ax=_ax, x=x, y=y, color=_color)\n",
    "    \n",
    "\n",
    "plot_mapping(dgs_ka2score, pal[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mapping(dgs_group2score, pal[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev1_df = df.loc[df['Title'].str.contains(\"Full Stack Developer - Fully remote\", case=False)]\n",
    "dev1_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_doc = dev1_df['Description'].values[0]\n",
    "dev1_ka2score = map(mapper, query_doc)\n",
    "dev1_group2score = map_groups(kg_mapper, query_doc)\n",
    "plot_mapping(dev1_ka2score, pal[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mapping(dev1_group2score, pal[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_df = df.loc[df['Title'].str.contains(\"IT Support\", case=False)]\n",
    "it_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_doc = it_df['Description'].values[0]\n",
    "it_ka2score = map(mapper, query_doc)\n",
    "it_group2score = map_groups(kg_mapper, query_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df = df.loc[df['Title'].str.contains(\"Software Test Engineer\", case=False)]\n",
    "qa_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_doc = qa_df['Description'].values[0]\n",
    "qa_ka2score = map(mapper, query_doc)\n",
    "qa_group2score = map_groups(kg_mapper, query_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devops_df = df.loc[df['Title'].str.contains(\"Cloud DevOps\", case=False)]\n",
    "devops_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_doc = devops_df['Description'].values[0]\n",
    "devops_ka2score = map(mapper, query_doc)\n",
    "devops_group2score = map_groups(kg_mapper, query_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = df.loc[df['Title'].str.contains(\"Senior Data Scientist\", case=False)]\n",
    "data_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_doc = data_df['Description'].values[0]\n",
    "data_ka2score = map(mapper, query_doc)\n",
    "data_group2score = map_groups(kg_mapper, query_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_df = df.loc[df['Title'].str.contains(\"IT Security Analyst\", case=False)]\n",
    "sec_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_doc = sec_df['Description'].values[0]\n",
    "sec_ka2score = map(mapper, query_doc)\n",
    "sec_group2score = map_groups(kg_mapper, query_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "man_df = df.loc[df['Title'].str.contains(\"Agile Delivery Manager\", case=False)]\n",
    "man_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_doc = man_df['Description'].values[0]\n",
    "man_ka2score = map(mapper, query_doc)\n",
    "man_group2score = map_groups(kg_mapper, query_doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make radar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_normalise(a):\n",
    "    amin, amax = min(a), max(a)\n",
    "    for i, val in enumerate(a):\n",
    "        a[i] = (val-amin) / (amax-amin)\n",
    "\n",
    "categories = list(dev1_group2score.keys())\n",
    "categories = [*categories, categories[0]]\n",
    "\n",
    "dev = list(dev1_group2score.values())\n",
    "dev = [*dev, dev[0]]\n",
    "quick_normalise(dev)\n",
    "\n",
    "dgs = list(dgs_group2score.values())\n",
    "dgs = [*dgs, dgs[0]]\n",
    "quick_normalise(dgs)\n",
    "\n",
    "it = list(it_group2score.values())\n",
    "it = [*it, it[0]]\n",
    "quick_normalise(it)\n",
    "\n",
    "qa = list(qa_group2score.values())\n",
    "qa = [*qa, qa[0]]\n",
    "quick_normalise(qa)\n",
    "\n",
    "devops = list(devops_group2score.values())\n",
    "devops = [*devops, devops[0]]\n",
    "quick_normalise(devops)\n",
    "\n",
    "man = list(man_group2score.values())\n",
    "man = [*man, man[0]]\n",
    "quick_normalise(man)\n",
    "\n",
    "sec = list(sec_group2score.values())\n",
    "sec = [*sec, sec[0]]\n",
    "quick_normalise(sec)\n",
    "\n",
    "data = list(data_group2score.values())\n",
    "data = [*data, data[0]]\n",
    "quick_normalise(data)\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatterpolar(r=dev, theta=categories, name='Dev', line_color=pal[0], line_width=5, marker_size=12),\n",
    "        go.Scatterpolar(r=dgs, theta=categories, name='Other', line_color=pal[1], line_width=5, marker_size=12),\n",
    "        go.Scatterpolar(r=it, theta=categories, name='IT', line_color=pal[7], line_width=5, marker_size=12),\n",
    "        go.Scatterpolar(r=qa, theta=categories, name='QA', line_color=pal[6], line_width=5, marker_size=12),\n",
    "        go.Scatterpolar(r=devops, theta=categories, name='DevOps', line_color=pal[3], line_width=5, marker_size=12),\n",
    "        go.Scatterpolar(r=man, theta=categories, name='Man', line_color=pal[2], line_width=5, marker_size=12),\n",
    "        go.Scatterpolar(r=sec, theta=categories, name='Security', line_color=pal[4], line_width=5, marker_size=12),\n",
    "        go.Scatterpolar(r=data, theta=categories, name='Data', line_color=pal[5], line_width=5, marker_size=12),\n",
    "    ],\n",
    "    layout=go.Layout(\n",
    "        title=go.layout.Title(text='Illustrative mappings'),\n",
    "        polar={'radialaxis': {'visible': True}},\n",
    "        showlegend=True\n",
    "    )\n",
    ")\n",
    "\n",
    "pyo.plot(fig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make subplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 2, figsize=(8.27, 16.69))\n",
    "\n",
    "trim = 6\n",
    "\n",
    "axes[0, 0].set_title('Dev')\n",
    "axes[0, 1].set_title('Other')\n",
    "axes[1, 0].set_title('IT')\n",
    "axes[1, 1].set_title('QA')\n",
    "axes[2, 0].set_title('DevOps')\n",
    "axes[2, 1].set_title('Manager')\n",
    "axes[3, 0].set_title('Security')\n",
    "axes[3, 1].set_title('Data')\n",
    "\n",
    "\n",
    "plot_mapping(dev1_ka2score, pal[0], _ax=axes[0, 0], trim=trim)\n",
    "plot_mapping(dgs_ka2score, pal[1], _ax=axes[0, 1], trim=trim)\n",
    "plot_mapping(it_ka2score, pal[7], _ax=axes[1, 0], trim=trim)\n",
    "plot_mapping(qa_ka2score, pal[6], _ax=axes[1, 1], trim=trim)\n",
    "plot_mapping(devops_ka2score, pal[3], _ax=axes[2, 0], trim=trim)\n",
    "plot_mapping(man_ka2score, pal[2], _ax=axes[2, 1], trim=trim)\n",
    "plot_mapping(sec_ka2score, pal[4], _ax=axes[3, 0], trim=trim)\n",
    "plot_mapping(data_ka2score, pal[5], _ax=axes[3, 1], trim=trim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot avg. mappings (by type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_type(job_type):\n",
    "    if job_type == 'IR' or job_type == 'Security analyst' or job_type == 'Sys Admin':\n",
    "        return 'Security'\n",
    "    elif job_type == 'Se' or job_type == 'SE':\n",
    "        return 'Dev'\n",
    "    elif job_type == 'Management':\n",
    "        return 'Manager'\n",
    "    elif job_type == 'Business analyst':\n",
    "        return 'Data'\n",
    "    elif job_type == 'Sales' or job_type == 'Researcher' or job_type == 'Design' or job_type == 'Consultant':\n",
    "        return 'Other'\n",
    "    else:\n",
    "        return job_type\n",
    "    \n",
    "\n",
    "df['Job Type'] = df['Type'].apply(lambda t: map_type(t))\n",
    "\n",
    "data = []\n",
    "for index, row in df.iterrows():\n",
    "    scores = map_groups(kg_mapper, row['Description'])\n",
    "    scores['Job Type'] = row['Job Type']\n",
    "    data.append(scores)\n",
    "\n",
    "combined_df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "combined_df = combined_df.rename(columns=ka2long)\n",
    "\n",
    "melt_df = combined_df.melt(id_vars=['Job Type'])\n",
    "melt_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8.27, 11.69))\n",
    "\n",
    "axis_labels = ['Similarity Score', '']\n",
    "data_labels = []\n",
    "\n",
    "plt.xticks(fontsize=10, color='DimGrey')\n",
    "plt.yticks(fontsize=10, color='DimGrey')\n",
    "plt.gca().spines['left'].set_color('DimGrey')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_color('DimGrey')\n",
    "\n",
    "sns.boxenplot(data=melt_df, orient='h', width=.75, x='value', y='variable', hue='Job Type', showfliers=False, palette=[pal[0], pal[6], pal[3], pal[2], pal[4], pal[5], pal[1], pal[7]])\n",
    "\n",
    "plt.xlabel(axis_labels[0], fontsize=12, color='DimGrey', loc='left')\n",
    "plt.ylabel(axis_labels[1], fontsize=12, color='DimGrey', loc='top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for index, row in df.iterrows():\n",
    "    scores = map(mapper, row['Description'])\n",
    "    scores['Job Type'] = row['Job Type']\n",
    "    data.append(scores)\n",
    "\n",
    "combined_df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "combined_df = combined_df.rename(columns=ka2long)\n",
    "\n",
    "melt_df = combined_df.melt(id_vars=['Job Type'])\n",
    "melt_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8.27, 11.69))\n",
    "\n",
    "axis_labels = ['Similarity Score', '']\n",
    "data_labels = []\n",
    "\n",
    "plt.xticks(fontsize=10, color='DimGrey')\n",
    "plt.yticks(fontsize=10, color='DimGrey')\n",
    "plt.gca().spines['left'].set_color('DimGrey')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_color('DimGrey')\n",
    "\n",
    "sns.boxenplot(data=melt_df, orient='h', width=.75, x='value', y='variable', hue='Job Type', showfliers=False)\n",
    "\n",
    "plt.xlabel(axis_labels[0], fontsize=12, color='DimGrey', loc='left')\n",
    "plt.ylabel(axis_labels[1], fontsize=12, color='DimGrey', loc='top')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
